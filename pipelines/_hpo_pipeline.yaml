metadata:
  name: "cpetformer_pipeline"
  vars:
    RUNS_DIR: "{EXPERIMENT_HOME}"
    RUN_DIR: "{run_dir}"
    eval_conf_dir: "{CONFIGS_DIR}/eval"

    subset_data: "{subset_data}"
    full_data: "{full_data}"
    data_file_loco: "{data_file_loco}"
    hpo_trials: "{hpo_trials}"
    hpo_jobs: "{hpo_jobs}"
    optuna_seed: "{optuna_seed}"
    robust_seeds: "{robust_seeds}"
    sprint_epochs: "{sprint_epochs}"
    full_epochs: "{full_epochs}"
    batch_size: "{batch_size}"
    top_k: "{top_k}"
  envs:
    PYTHONUNBUFFERED: "1"
    PYTHONPATH: "{EXPERIMENT_HOME}/src"
    CPETX_PROJECT_ROOT: "{EXPERIMENT_HOME}"
    CONFIGS_DIR: "{EXPERIMENT_HOME}/configs"

steps:
  - id: prepare-run
    type: shell
    description: "Create pipeline directories and record run metadata."
    vars:
      STEP_DIR: "{RUN_DIR}/prepare-run"
    command: |
      set -e
      mkdir -p "{RUN_DIR}" "{RUN_DIR}/reports" "{STEP_DIR}"
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py write-info \
        --pipeline-root "{RUN_DIR}" \
        --step-dir "{STEP_DIR}" \
        --pipeline-name "{pipeline_name}" \
        --model "{model}" \
        --baseline-arch "{baseline_arch}" \
        --subset-data "{subset_data}" \
        --full-data "{full_data}" \
        --sprint-epochs "{sprint_epochs}" \
        --full-epochs "{full_epochs}" \
        --batch-size "{batch_size}" \
        --top-k "{top_k}" \
        --hpo-trials "{hpo_trials}" \
        --hpo-jobs "{hpo_jobs}" \
        --optuna-seed "{optuna_seed}" \
        --robust-seeds "{robust_seeds}"

  - id: optuna-search
    type: shell
    depends_on: [prepare-run]
    description: "Run Optuna/ASHA hyperparameter search."
    vars:
      STEP_DIR: "{RUN_DIR}/optuna"
    command: |
      set -e
      mkdir -p "{STEP_DIR}"
      ARCH="^{model}$"
      STORAGE="sqlite:///{RUN_DIR}/optuna/optuna.db"
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/hpo_optuna.py \
        --arch "${ARCH}" \
        --subset-data "{subset_data}" \
        --full-data "{full_data}" \
        --configs-dir "{CONFIGS_DIR}" \
        --run-dir "{RUN_DIR}" \
        --sprint-epochs {sprint_epochs} \
        --batch-size {batch_size} \
        --n-trials {hpo_trials} \
        --n-jobs {hpo_jobs} \
        --top-k {top_k} \
        --seed {optuna_seed} \
        --study "{model}_optuna" \
        --storage "${STORAGE}"

  - id: full-train
    type: shell
    depends_on: [optuna-search]
    description: "Train selected combinations with full training configuration."
    vars:
      STEP_DIR: "{RUN_DIR}/full-train"
    command: |
      set -e
      mkdir -p "{STEP_DIR}"
      CANDIDATES_JSON="{RUN_DIR}/reports/top_full_candidates.json"
      if [ ! -f "${CANDIDATES_JSON}" ]; then
        echo "[full-train] candidates not found, abort."
        exit 1
      fi
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py emit-candidates \
        --pipeline-root "{RUN_DIR}" \
        --output "{STEP_DIR}/candidates.txt" \
        --default-arch "{model}"
      TAB="$(printf '\t')"
      SEED_LIST="{robust_seeds}"
      while IFS="${TAB}" read -r ARCH_ID COMBO LR WD CLIP; do
        [ -z "${ARCH_ID}" ] && continue
        TAG="${COMBO:-lr${LR}_wd${WD}_clip${CLIP}}"
        for SEED in ${SEED_LIST}; do
          RUN_TAG="${TAG}_seed${SEED}"
          RUN_ROOT="{STEP_DIR}/${RUN_TAG}"
          mkdir -p "${RUN_ROOT}/artifacts" "${RUN_ROOT}/logs" "${RUN_ROOT}/results"
          echo "[full-train] ${ARCH_ID} :: ${RUN_TAG}"
          if WEIGHT_DECAY=${WD} GRAD_CLIP_MAX_NORM=${CLIP} PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/vox_cpet/cmd/cpetx-model train \
            --data-file {full_data} \
            --conf {CONFIGS_DIR}/model \
            --filter "^${ARCH_ID}$" \
            --run-dir "${RUN_ROOT}" \
            --save-dir "${RUN_ROOT}/artifacts" \
            --log-dir "${RUN_ROOT}/logs" \
            --task-id "{TASK_ID}_${ARCH_ID}_${RUN_TAG}_full" \
            --num-epochs {full_epochs} \
            --learning-rate "${LR}" \
            --batch-size {batch_size} \
            --seed "${SEED}"; then
            PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py write-meta \
              --run-root "${RUN_ROOT}" \
              --arch "${ARCH_ID}" \
              --combo "${TAG}" \
              --learning-rate "${LR}" \
              --weight-decay "${WD}" \
              --grad-clip "${CLIP}" \
              --stage "full" \
              --seed "${SEED}"
          else
            echo "[full-train] ${ARCH_ID} :: ${RUN_TAG} failed, skipping to next seed" >&2
            continue
          fi
        done
      done < "{STEP_DIR}/candidates.txt"

  - id: full-eval
    type: shell
    depends_on: [full-train]
    description: "Evaluate full training checkpoints and aggregate LOCO metrics."
    vars:
      STEP_DIR: "{RUN_DIR}/full-eval"
    command: |
      set -e
      ARCH="{model}"
      find "{RUN_DIR}/full-train" -mindepth 1 -maxdepth 1 -type d | while read -r COMBO_DIR; do
        COMBO="$(basename "${COMBO_DIR}")"
        RUN_ROOT="{STEP_DIR}/${COMBO}"
        mkdir -p "${RUN_ROOT}/logs" "${RUN_ROOT}/results"
        echo "[full-eval] ${ARCH} :: ${COMBO}"
        if PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/vox_cpet/cmd/cpetx-model eval \
          --task-id "{TASK_ID}_${ARCH}_${COMBO}_full" \
          --conf {eval_conf_dir} \
          --data-file {full_data} \
          --filter "^${ARCH}$" \
          --run-dir "${RUN_ROOT}" \
          --save-dir "${RUN_ROOT}/results" \
          --log-dir "${RUN_ROOT}/logs" \
          --checkpoints-path "${COMBO_DIR}/artifacts"; then

          PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py copy-meta \
            --source-dir "${COMBO_DIR}" \
            --run-root "${RUN_ROOT}"
          if [ -d "{data_file_loco}" ]; then
            LOCO_SUB="${RUN_ROOT}/loco"
            mkdir -p "${LOCO_SUB}"
            PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/aggregate_loco_metrics.py "${LOCO_SUB}" "${ARCH}" || true
          fi
        else
          echo "[full-eval] ${ARCH} :: ${COMBO} failed, skipping evaluation summary" >&2
          continue
        fi
      done

  - id: full-summarize
    type: shell
    depends_on: [full-eval]
    description: "Summarize full training results and record best configuration."
    vars:
      STEP_DIR: "{RUN_DIR}/full-summarize"
    command: |
      set -e
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py summarize-full \
        --pipeline-root "{RUN_DIR}" \
        --step-dir "{STEP_DIR}"
