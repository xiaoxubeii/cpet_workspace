metadata:
  name: "cpetformer_pipeline"
  vars:
    RUNS_DIR: "{EXPERIMENT_HOME}"
    RUN_DIR: "{run_dir}"
    eval_conf_dir: "{CONFIGS_DIR}/eval"

    subset_data: "/home/cheng/workspace/cpetx_workspace/generate_dataset/artifacts/cpet_dataset_small.h5"
    full_data: "/home/cheng/workspace/cpetx_workspace/generate_dataset/artifacts/cpet_dataset.h5"
    data_file_loco: "/home/cheng/workspace/cpetx_workspace/generate_dataset/artifacts/cpet_dataset_loco"
  envs:
    PYTHONUNBUFFERED: "1"
    PYTHONPATH: "{EXPERIMENT_HOME}/src"
    CPETX_PROJECT_ROOT: "{EXPERIMENT_HOME}"
    CONFIGS_DIR: "{EXPERIMENT_HOME}/configs"

steps:
  - id: prepare-run
    type: shell
    description: "Create pipeline directories and record run metadata."
    vars:
      STEP_DIR: "{RUN_DIR}/prepare-run"
    command: |
      set -e
      mkdir -p "{RUN_DIR}" "{RUN_DIR}/reports" "{STEP_DIR}"
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py write-info \
        --pipeline-root "{RUN_DIR}" \
        --step-dir "{STEP_DIR}" \
        --pipeline-name "{pipeline_name}" \
        --model "{model}" \
        --baseline-arch "{baseline_arch}" \
        --subset-data "{subset_data}" \
        --full-data "{full_data}" \
        --lr-grid "{lr_grid}" \
        --wd-grid "{wd_grid}" \
        --grad-clip-grid "{grad_clip_grid}" \
        --sprint-epochs "{sprint_epochs}" \
        --full-epochs "{full_epochs}" \
        --batch-size "{batch_size}" \
        --top-k "{top_k}"

  - id: sprint-train
    type: shell
    depends_on: [prepare-run]
    description: "Run short training loops across a small hyperparameter grid."
    vars:
      STEP_DIR: "{RUN_DIR}/sprint-train"
    command: |
      set -e
      ARCH="{model}"
      DATA_FILE="{subset_data}"
      if [ ! -f "${DATA_FILE}" ]; then
        echo "[sprint-train] subset data ${DATA_FILE} missing, fallback to full dataset."
        DATA_FILE="{full_data}"
      fi
      for LR in {lr_grid}; do
        for WD in {wd_grid}; do
          for CLIP in {grad_clip_grid}; do
            COMBO="lr${LR}_wd${WD}_clip${CLIP}"
            RUN_ROOT="{STEP_DIR}/${COMBO}"
            mkdir -p "${RUN_ROOT}/logs" "${RUN_ROOT}/results"
            echo "[sprint-train] ${ARCH} :: ${COMBO}"
            WEIGHT_DECAY=${WD} GRAD_CLIP_MAX_NORM=${CLIP} PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/vox_cpet/cmd/cpetx-model train \
              --data-file "${DATA_FILE}" \
              --conf {CONFIGS_DIR}/model \
              --filter "^${ARCH}$" \
              --run-dir "${RUN_ROOT}" \
              --save-dir "${RUN_ROOT}/artifacts" \
              --log-dir "${RUN_ROOT}/logs" \
              --task-id "{TASK_ID}_${ARCH}_${COMBO}_sprint" \
              --num-epochs {sprint_epochs} \
              --learning-rate "${LR}" \
              --batch-size {batch_size}
            PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py write-meta \
              --run-root "${RUN_ROOT}" \
              --arch "${ARCH}" \
              --combo "${COMBO}" \
              --learning-rate "${LR}" \
              --weight-decay "${WD}" \
              --grad-clip "${CLIP}" \
              --stage "sprint"
          done
        done
      done

  - id: sprint-eval
    type: shell
    depends_on: [sprint-train]
    description: "Evaluate sprint checkpoints."
    vars:
      STEP_DIR: "{RUN_DIR}/sprint-eval"
    command: |
      set -e
      ARCH="{model}"
      find "{RUN_DIR}/sprint-train" -mindepth 1 -maxdepth 1 -type d | while read -r COMBO_DIR; do
        COMBO="$(basename "${COMBO_DIR}")"
        RUN_ROOT="{STEP_DIR}/${COMBO}"
        mkdir -p "${RUN_ROOT}/logs" "${RUN_ROOT}/results"
        echo "[sprint-eval] ${ARCH} :: ${COMBO}"
        PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/vox_cpet/cmd/cpetx-model eval \
          --task-id "{TASK_ID}_${ARCH}_${COMBO}_sprint" \
          --conf {eval_conf_dir} \
          --data-file {full_data} \
          --filter "^${ARCH}$" \
          --run-dir "${RUN_ROOT}" \
          --save-dir "${RUN_ROOT}/results" \
          --log-dir "${RUN_ROOT}/logs" \
          --checkpoints-path "${COMBO_DIR}/artifacts"
        PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py copy-meta \
          --source-dir "${COMBO_DIR}" \
          --run-root "${RUN_ROOT}"
      done

  - id: sprint-summarize
    type: shell
    depends_on: [sprint-eval]
    description: "Aggregate sprint results and select top combinations."
    vars:
      STEP_DIR: "{RUN_DIR}/sprint-summarize"
    command: |
      set -e
      mkdir -p "{STEP_DIR}"
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py summarize-sprint \
        --pipeline-root "{RUN_DIR}" \
        --step-dir "{STEP_DIR}" \
        --top-k "{top_k}"

  - id: full-train
    type: shell
    depends_on: [sprint-summarize]
    description: "Train selected combinations with full training configuration."
    vars:
      STEP_DIR: "{RUN_DIR}/full-train"
    command: |
      set -e
      mkdir -p "{STEP_DIR}"
      CANDIDATES_JSON="{RUN_DIR}/reports/top_full_candidates.json"
      if [ ! -f "${CANDIDATES_JSON}" ]; then
        echo "[full-train] candidates not found, abort."
        exit 1
      fi
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py emit-candidates \
        --pipeline-root "{RUN_DIR}" \
        --output "{STEP_DIR}/candidates.txt" \
        --default-arch "{model}"
      TAB="$(printf '\t')"
      while IFS="${TAB}" read -r ARCH_ID COMBO LR WD CLIP; do
        [ -z "${ARCH_ID}" ] && continue
        TAG="${COMBO:-lr${LR}_wd${WD}_clip${CLIP}}"
        RUN_ROOT="{STEP_DIR}/${TAG}"
        mkdir -p "${RUN_ROOT}/artifacts" "${RUN_ROOT}/logs" "${RUN_ROOT}/results"
        echo "[full-train] ${ARCH_ID} :: ${TAG}"
        WEIGHT_DECAY=${WD} GRAD_CLIP_MAX_NORM=${CLIP} PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/vox_cpet/cmd/cpetx-model train \
          --data-file {full_data} \
          --conf {CONFIGS_DIR}/model \
          --filter "^${ARCH_ID}$" \
          --run-dir "${RUN_ROOT}" \
          --save-dir "${RUN_ROOT}/artifacts" \
          --log-dir "${RUN_ROOT}/logs" \
          --task-id "{TASK_ID}_${ARCH_ID}_${TAG}_full" \
          --num-epochs {full_epochs} \
          --learning-rate "${LR}" \
          --batch-size {batch_size}
        PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py write-meta \
          --run-root "${RUN_ROOT}" \
          --arch "${ARCH_ID}" \
          --combo "${TAG}" \
          --learning-rate "${LR}" \
          --weight-decay "${WD}" \
          --grad-clip "${CLIP}" \
          --stage "full"
      done < "{STEP_DIR}/candidates.txt"

  - id: full-eval
    type: shell
    depends_on: [full-train]
    description: "Evaluate full training checkpoints and aggregate LOCO metrics."
    vars:
      STEP_DIR: "{RUN_DIR}/full-eval"
    command: |
      set -e
      ARCH="{model}"
      find "{RUN_DIR}/full-train" -mindepth 1 -maxdepth 1 -type d | while read -r COMBO_DIR; do
        COMBO="$(basename "${COMBO_DIR}")"
        RUN_ROOT="{STEP_DIR}/${COMBO}"
        mkdir -p "${RUN_ROOT}/logs" "${RUN_ROOT}/results"
        echo "[full-eval] ${ARCH} :: ${COMBO}"
        PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/vox_cpet/cmd/cpetx-model eval \
          --task-id "{TASK_ID}_${ARCH}_${COMBO}_full" \
          --conf {eval_conf_dir} \
          --data-file {full_data} \
          --filter "^${ARCH}$" \
          --run-dir "${RUN_ROOT}" \
          --save-dir "${RUN_ROOT}/results" \
          --log-dir "${RUN_ROOT}/logs" \
          --checkpoints-path "${COMBO_DIR}/artifacts"
            
        PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py copy-meta \
          --source-dir "${COMBO_DIR}" \
          --run-root "${RUN_ROOT}"
        # Optional LOCO aggregation if datasets exist
        if [ -d "{data_file_loco}" ]; then
          LOCO_SUB="${RUN_ROOT}/loco"
          mkdir -p "${LOCO_SUB}"
          PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/aggregate_loco_metrics.py "${LOCO_SUB}" "${ARCH_ID}" || true
        fi
      done

  - id: full-summarize
    type: shell
    depends_on: [full-eval]
    description: "Summarize full training results and record best configuration."
    vars:
      STEP_DIR: "{RUN_DIR}/full-summarize"
    command: |
      set -e
      PYTHONPATH={EXPERIMENT_HOME}/src python {EXPERIMENT_HOME}/src/scripts/pipeline_tasks.py summarize-full \
        --pipeline-root "{RUN_DIR}" \
        --step-dir "{STEP_DIR}"