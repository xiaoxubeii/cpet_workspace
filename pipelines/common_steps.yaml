templates:
  - id: rank-models-base
    type: shell
    description: "Update global ranking based on latest best-model reports."
    vars:
      STEP_DIR: "{RUN_DIR}/rank-models"
    depends_on: [collect-reports]
    command: |
      set -e
      mkdir -p "{STEP_DIR}"
      python - <<'PY'
      import csv
      import json
      from datetime import datetime
      from pathlib import Path

      def score_tuple(entry):
          def to_float(value, default):
              try:
                  return float(value)
              except (TypeError, ValueError):
                  return default

          mae = to_float(entry.get("mae"), float("inf"))
          rmse = to_float(entry.get("rmse"), float("inf"))
          r2 = entry.get("r2_score")
          r2_component = -to_float(r2, float("inf")) if r2 is not None else float("inf")
          return (mae, rmse, r2_component)

      def should_scan_all(value: str) -> bool:
          return value.strip().lower() in {"1", "true", "yes", "y", "on"}

      def derive_run_name(path: Path) -> str:
          parts = list(path.parts)
          if "sota" in parts:
              idx = parts.index("sota")
              if idx + 1 < len(parts):
                  return parts[idx + 1]
          return "{RUN_TS}"

      run_dir = Path("{RUN_DIR}")
      reports_root = run_dir / "reports"
      step_dir = Path("{STEP_DIR}")
      best_dir = Path("{BEST_DIR}")
      timestamp = datetime.utcnow().isoformat() + "Z"
      scan_all = should_scan_all("{rank_scan_all}")

      reports_root.mkdir(parents=True, exist_ok=True)
      best_dir.mkdir(parents=True, exist_ok=True)

      sources = []
      if scan_all:
          runs_root = Path("{RUNS_DIR}")
          if runs_root.exists():
              sources.extend(sorted(runs_root.glob("*/reports/*_best_model.json")))
      else:
          sources.extend(sorted(reports_root.glob("*_best_model.json")))

      records = []
      for best_file in sources:
          try:
              data = json.loads(best_file.read_text(encoding="utf-8"))
          except json.JSONDecodeError:
              continue

          entry = {
              "model": data.get("arch") or best_file.stem.replace("_best_model", ""),
              "combo": data.get("combo"),
              "learning_rate": data.get("learning_rate"),
              "weight_decay": data.get("weight_decay"),
              "grad_clip": data.get("grad_clip"),
              "mae": data.get("mae"),
              "rmse": data.get("rmse"),
              "r2_score": data.get("r2_score"),
              "correlation": data.get("correlation"),
              "mape": data.get("mape"),
              "subset_data": "{subset_data}",
              "full_data": "{full_data}",
              "sprint_epochs": "{sprint_epochs}",
              "full_epochs": "{full_epochs}",
              "source_file": str(best_file),
              "source_run": derive_run_name(best_file),
              "generated_at": data.get("generated_at"),
              "updated_at": timestamp,
          }
          records.append(entry)

      ranked_entries = []
      for rank, entry in enumerate(sorted(records, key=score_tuple), start=1):
          ranked = dict(entry)
          ranked["rank"] = rank
          ranked_entries.append(ranked)

      run_payload = {
          "generated_at": timestamp,
          "source_run": "{RUN_TS}",
          "scan_all": scan_all,
          "entries": ranked_entries,
      }

      run_json = step_dir / "model_ranking.json"
      run_json.write_text(json.dumps(run_payload, indent=2, ensure_ascii=False), encoding="utf-8")

      run_csv = step_dir / "model_ranking.csv"
      with run_csv.open("w", newline="", encoding="utf-8") as csvfile:
          writer = csv.writer(csvfile)
          writer.writerow(["rank", "model", "mae", "rmse", "r2_score", "mape", "correlation", "combo", "learning_rate", "weight_decay", "grad_clip", "subset_data", "full_data", "sprint_epochs", "full_epochs", "source_file", "source_run"])
          for entry in ranked_entries:
              writer.writerow([
                  entry.get("rank"),
                  entry.get("model"),
                  entry.get("mae"),
                  entry.get("rmse"),
                  entry.get("r2_score"),
                  entry.get("mape"),
                  entry.get("correlation"),
                  entry.get("combo"),
                  entry.get("learning_rate"),
                  entry.get("weight_decay"),
                  entry.get("grad_clip"),
                  entry.get("subset_data"),
                  entry.get("full_data"),
                  entry.get("sprint_epochs"),
                  entry.get("full_epochs"),
                  entry.get("source_file"),
                  entry.get("source_run"),
              ])

      last_run_path = best_dir / "model_ranking_last_run.json"
      last_run_path.write_text(json.dumps(run_payload, indent=2, ensure_ascii=False), encoding="utf-8")

      best_path = best_dir / "model_ranking.json"
      best_data = {}
      if best_path.exists():
          try:
              existing = json.loads(best_path.read_text(encoding="utf-8"))
              for item in existing.get("entries", []):
                  model = item.get("model")
                  if model:
                      best_data[model] = item
          except json.JSONDecodeError:
              pass

      for entry in ranked_entries:
          model = entry.get("model")
          if not model:
              continue
          candidate = dict(entry)
          candidate["updated_at"] = timestamp
          current = best_data.get(model)
          if current is None or score_tuple(candidate) < score_tuple(current):
              best_data[model] = candidate

      best_entries = sorted(best_data.values(), key=score_tuple)
      for idx, item in enumerate(best_entries, start=1):
          item["rank"] = idx

      best_payload = {
          "generated_at": timestamp,
          "entries": best_entries,
      }

      best_path.write_text(json.dumps(best_payload, indent=2, ensure_ascii=False), encoding="utf-8")

      best_csv = best_dir / "model_ranking.csv"
      with best_csv.open("w", newline="", encoding="utf-8") as csvfile:
          writer = csv.writer(csvfile)
          writer.writerow(["rank", "model", "mae", "rmse", "r2_score", "mape", "correlation", "combo", "learning_rate", "weight_decay", "grad_clip", "subset_data", "full_data", "sprint_epochs", "full_epochs", "source_run", "source_file", "updated_at"])
          for entry in best_entries:
              writer.writerow([
                  entry.get("rank"),
                  entry.get("model"),
                  entry.get("mae"),
                  entry.get("rmse"),
                  entry.get("r2_score"),
                  entry.get("mape"),
                  entry.get("correlation"),
                  entry.get("combo"),
                  entry.get("learning_rate"),
                  entry.get("weight_decay"),
                  entry.get("grad_clip"),
                  entry.get("subset_data"),
                  entry.get("full_data"),
                  entry.get("sprint_epochs"),
                  entry.get("full_epochs"),
                  entry.get("source_run"),
                  entry.get("source_file"),
                  entry.get("updated_at"),
              ])

      for entry in best_entries:
          model = entry.get("model")
          if not model:
              continue
          (best_dir / f"{model}.json").write_text(json.dumps(entry, indent=2, ensure_ascii=False), encoding="utf-8")
      PY